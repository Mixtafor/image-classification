{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d9439ff",
   "metadata": {},
   "source": [
    "# Свёрточные нейросети — классификация изображений (TensorFlow)\n",
    "### 1. Инициализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ae94ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорт необходимых библиотек и модулей\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout, Input\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Проверка версии TensorFlow\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de8802b",
   "metadata": {},
   "source": [
    "### 2. Загрузка датасета\n",
    "Используем датасет [CIFAR‑10](https://www.cs.toronto.edu/~kriz/cifar.html) — классический бенчмарк для задач компьютерного зрения. В нём 60 000 цветных изображений 32×32 в 10 классах (по 6 000 изображений на класс). Датасет широко применяется для обучения и проверки алгоритмов классификации изображений.\n",
    "\n",
    "Классы: самолёт, автомобиль, птица, кошка, олень, собака, лягушка, лошадь, корабль и грузовик."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b9600b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка датасета из библиотеки Keras\n",
    "from keras.datasets import cifar10 \n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Проверка формы загруженных данных\n",
    "print(\"X Train: {} \\nX Test: {} \\ny Train: {} \\ny test: {}\".format(X_train.shape, X_test.shape, y_train.shape, y_test.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c0289d",
   "metadata": {},
   "source": [
    "Как видно выше, доступно 50 000 обучающих и 10 000 тестовых изображений, каждое размера 32×32 пикселя с тремя цветовыми каналами (RGB). Метки классов присутствуют для обучающей и тестовой выборок и заданы в виде одномерных столбцов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c8f2ee",
   "metadata": {},
   "source": [
    "### 3. Предобработка изображений\n",
    "Так как модель CNN решает многоклассовую задачу, целевые метки должны быть совместимы с выходом сети. Поэтому преобразуем метки классов в one‑hot представление, удобное для обучения нейросети."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2267af24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразование целевых меток к one-hot кодированию\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8affba77",
   "metadata": {},
   "source": [
    "Выполним аугментацию и преобразования изображений, чтобы уменьшить переобучение и повысить обобщающую способность модели.\n",
    "\n",
    "Трансформации для обучающих изображений:\n",
    "- Масштабирование пикселей к диапазону [0, 1];\n",
    "- Случайный сдвиг по сдвигу (shear);\n",
    "- Случайный зум;\n",
    "- Случайное горизонтальное отражение.\n",
    "\n",
    "Тестовые изображения не аугментируются — только нормируются, чтобы избежать утечки данных и корректно оценивать качество."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e739e36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Инициализация генератора изображений для обучения\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    shear_range = 0.2,\n",
    "    zoom_range = 0.2,\n",
    "    horizontal_flip = True\n",
    ")\n",
    "\n",
    "# Генерация батчей аугментированных обучающих данных\n",
    "train_generator = train_datagen.flow(\n",
    "    X_train, y_train,\n",
    "    batch_size = 32\n",
    ")\n",
    "\n",
    "# Инициализация генератора изображений для теста (только масштабирование)\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255\n",
    ")\n",
    "\n",
    "# Генерация батчей тестовых данных\n",
    "test_generator = test_datagen.flow(\n",
    "    X_test, y_test,\n",
    "    batch_size = 32\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fceb81",
   "metadata": {},
   "source": [
    "### 4. Построение модели CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccd96dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Инициализация модели CNN\n",
    "# Инициализация последовательной модели\n",
    "cnn = Sequential()\n",
    "\n",
    "#### Входной слой\n",
    "# Добавляем входной слой\n",
    "cnn.add(Input(shape=(32, 32, 3)))\n",
    "\n",
    "#### Свёрточные слои\n",
    "# Используем 2 свёрточных слоя с увеличением числа фильтров, чтобы модель улавливала более сложные паттерны.\n",
    "# За свёрточными слоями следуют слои максимального пуллинга, уменьшающие пространственные размеры карт признаков и частично\n",
    "# снижающие переобучение за счёт устойчивости к сдвигам.\n",
    "\n",
    "# Добавляем первый свёрточный слой\n",
    "cnn.add(Conv2D(filters=32, kernel_size=(3,3), strides=(1,1), activation=\"relu\"))\n",
    "# Добавляем первый слой пуллинга\n",
    "cnn.add(MaxPool2D(pool_size=(2,2), strides=2))\n",
    "# Добавляем второй свёрточный слой\n",
    "cnn.add(Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), activation=\"relu\"))\n",
    "# Добавляем второй слой пуллинга\n",
    "cnn.add(MaxPool2D(pool_size=(2,2), strides=2))\n",
    "\n",
    "#### Слой «выпрямления» (Flatten)\n",
    "# Этот слой преобразует выход свёрточных слоёв в одномерный вектор для передачи в полносвязные слои.\n",
    "cnn.add(Flatten())\n",
    "\n",
    "#### Полносвязные слои\n",
    "# Первый полносвязный слой обучается высокоуровневым признакам из «выпрямленного» входа,\n",
    "# второй помогает дополнительно уточнить представления.\n",
    "cnn.add(Dense(units=128, activation=\"relu\"))\n",
    "cnn.add(Dense(units=64, activation=\"relu\"))\n",
    "\n",
    "#### Выходной слой\n",
    "# Финальный слой на 10 нейронов (по числу классов) с softmax для вероятностей классов.\n",
    "cnn.add(Dense(units=10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d977ea",
   "metadata": {},
   "source": [
    "### 5. Обучение модели CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931e4335",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Компиляция модели CNN\n",
    "# Компилируем последовательную модель\n",
    "cnn.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\n",
    "        tf.keras.metrics.CategoricalAccuracy(name='accuracy'),\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall')\n",
    "    ]\n",
    ")\n",
    "\n",
    "#### Обучение модели CNN\n",
    "# Обучаем модель на сгенерированных аугментированных данных\n",
    "history = cnn.fit(\n",
    "    train_generator,\n",
    "    epochs=25,\n",
    "    validation_data=test_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c874e216",
   "metadata": {},
   "source": [
    "### 6. Анализ качества"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25c5acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Графики точности на обучении и валидации\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626a0d97",
   "metadata": {},
   "source": [
    "Наблюдения по результатам:\n",
    "- Точность на обучении последовательно растёт — модель осваивает задачу.\n",
    "- Валидационная точность поначалу увеличивается, затем начинает колебаться — возможный признак надвигающегося переобучения.\n",
    "- После пика (примерно около 9‑й эпохи) разрыв между обучением и валидацией расширяется.\n",
    "- Чтобы бороться с переобучением, имеет смысл добавить регуляризацию (например, dropout, weight decay), раннюю остановку и/или усилить аугментации.\n",
    "\n",
    "**Итог.** Модель демонстрирует уверенное начальное обучение, но позднее появляются симптомы переобучения. Для лучшей обобщающей способности полезно усилить регуляризацию и аккуратно настроить гиперпараметры (включая раннюю остановку)."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}