{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76db2057",
   "metadata": {},
   "source": [
    "# Свёрточные нейросети — классификация изображений (PyTorch)\n",
    "### 1. Инициализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f92ebb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорт необходимых библиотек и модулей\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "# Проверка версии PyTorch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e90c05",
   "metadata": {},
   "source": [
    "### 2. Загрузка и преобразование датасета\n",
    "Здесь используется датасет [CIFAR‑10](https://www.cs.toronto.edu/~kriz/cifar.html) — популярный бенчмарк в компьютерном зрении. Он содержит 60 000 цветных изображений 32×32 в 10 классах (по 6 000 изображений на класс) и часто применяется для обучения и оценки моделей классификации изображений.\n",
    "\n",
    "Классы: самолёт, автомобиль, птица, кошка, олень, собака, лягушка, лошадь, корабль и грузовик.\n",
    "\n",
    "Перед загрузкой данных зададим аугментации и преобразования, чтобы снизить переобучение и улучшить обобщающую способность CNN.\n",
    "\n",
    "Трансформации обучающих изображений:\n",
    "- Случайные повороты;\n",
    "- Случайные горизонтальные отражения;\n",
    "- Случайные изменения яркости/контраста/насыщенности/оттенка (color jitter);\n",
    "- Преобразование в тензор и нормализация значений.\n",
    "\n",
    "Тестовые изображения не аугментируются: мы только приводим их к тензору и нормируем, чтобы честно оценивать качество.\n",
    "\n",
    "Разделив конвейеры преобразований для обучения и теста, мы обучаемся на «обогащённых» данных, а оцениваемся на стабильных и неизменённых примерах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a507c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание трансформера для обучающих данных как последовательности шагов\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Создание трансформера для тестовых данных (без аугментации)\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be24bc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка датасета из библиотеки PyTorch\n",
    "data_train = torchvision.datasets.CIFAR10(root=\"../data/raw\", train=True, download=True, transform=transform_train)\n",
    "data_test = torchvision.datasets.CIFAR10(root=\"../data/raw\", train=False, download=True, transform=transform_test)\n",
    "\n",
    "# Инициализация загрузчиков данных\n",
    "train_loader = torch.utils.data.DataLoader(data_train, batch_size=32, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(data_test, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813b9cd4",
   "metadata": {},
   "source": [
    "### 3. Построение модели CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6435dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        \n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        # Определяем свёрточные слои\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # Определяем слои пуллинга\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        \n",
    "        # Определяем полносвязные слои\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 128)  # 8 * 8 * 6 — «сплющенное» измерение после пуллинга (из исходного комментария)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)  # 10 выходов под 10 классов\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Применяем свёртки с ReLU и пуллингом\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        \n",
    "        # «Сплющиваем» выход свёрточных слоёв\n",
    "        x = x.view(-1, 64 * 8 * 8)\n",
    "        \n",
    "        # Полносвязные слои с ReLU\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        \n",
    "        # Выходной слой (логиты классов)\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Инициализируем модель\n",
    "cnn = CNN()\n",
    "\n",
    "# Функция потерь\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Оптимизатор (Adam)\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b462a714",
   "metadata": {},
   "source": [
    "### 4. Обучение модели CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88a0a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Инициализация функции расчёта метрик\n",
    "def compute_metrics(outputs, labels):\n",
    "     # Преобразуем выходы модели в предсказанные метки\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    \n",
    "    # Перенос меток и предсказаний на CPU и в numpy\n",
    "    labels = labels.cpu().numpy()\n",
    "    preds = preds.cpu().numpy()\n",
    "    \n",
    "    # Вычисляем accuracy, F1, precision и recall\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds, average='weighted')\n",
    "    precision = precision_score(labels, preds, average='weighted', zero_division=1)\n",
    "    recall = recall_score(labels, preds, average='weighted', zero_division=1)\n",
    "    \n",
    "    return accuracy, f1, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c08bd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Число эпох обучения\n",
    "num_epochs = 25\n",
    "\n",
    "# Проверяем доступность GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Переносим модель на доступное устройство\n",
    "cnn.to(device)\n",
    "\n",
    "# Переключаем модель в режим обучения\n",
    "cnn.train()\n",
    "\n",
    "# Списки для хранения метрик обучения и валидации\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "# Основной цикл обучения\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    running_accuracy = 0.0\n",
    "    running_f1 = 0.0\n",
    "    running_precision = 0.0\n",
    "    running_recall = 0.0\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        \n",
    "         # Переносим батч на устройство\n",
    "        inputs, labels = inputs.to(device), labels.to(device)     \n",
    "        \n",
    "        # Обнуляем градиенты параметров\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Прямой проход: считаем выход модели\n",
    "        outputs = cnn(inputs)\n",
    "        \n",
    "        # Считаем функцию потерь\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Обратное распространение: считаем градиенты\n",
    "        loss.backward()\n",
    "        \n",
    "        # Обновляем параметры модели\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Накопление лосса\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # Вычисляем метрики\n",
    "        accuracy, f1, precision, recall = compute_metrics(outputs, labels)\n",
    "        running_accuracy += accuracy\n",
    "        running_f1 += f1\n",
    "        running_precision += precision\n",
    "        running_recall += recall\n",
    "\n",
    "    # Средние метрики за эпоху\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    avg_accuracy = running_accuracy / len(train_loader)\n",
    "    avg_f1 = running_f1 / len(train_loader)\n",
    "    avg_precision = running_precision / len(train_loader)\n",
    "    avg_recall = running_recall / len(train_loader)\n",
    "    \n",
    "#     Сохраняем точность обучения\n",
    "    train_accuracies.append(avg_accuracy)\n",
    "    \n",
    "   # Переключаемся в режим валидации\n",
    "    cnn.eval()\n",
    "    \n",
    "    # Инициализация метрик на валидации\n",
    "    eval_loss = 0.0\n",
    "    eval_accuracy = 0.0\n",
    "    eval_f1 = 0.0\n",
    "    eval_precision = 0.0\n",
    "    eval_recall = 0.0\n",
    "    \n",
    "    # На валидации градиенты не считаем\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            \n",
    "            # Переносим батч на устройство\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Прямой проход: выход модели\n",
    "            outputs = cnn(inputs)\n",
    "            \n",
    "            # Функция потерь\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Накопление лосса на валидации\n",
    "            eval_loss += loss.item()\n",
    "            \n",
    "            # Метрики\n",
    "            accuracy, f1, precision, recall = compute_metrics(outputs, labels)\n",
    "            eval_accuracy += accuracy\n",
    "            eval_f1 += f1\n",
    "            eval_precision += precision\n",
    "            eval_recall += recall\n",
    "    \n",
    "    # Средние метрики на валидации\n",
    "    avg_eval_loss = eval_loss / len(test_loader)\n",
    "    avg_eval_accuracy = eval_accuracy / len(test_loader)\n",
    "    avg_eval_f1 = eval_f1 / len(test_loader)\n",
    "    avg_eval_precision = eval_precision / len(test_loader)\n",
    "    avg_eval_recall = eval_recall / len(test_loader)\n",
    "    \n",
    "    # Сохраняем точность валидации\n",
    "    val_accuracies.append(avg_eval_accuracy)\n",
    "    \n",
    "    # Печать усреднённых метрик\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
    "          f'accuracy: {avg_accuracy:.4f} - f1_score: {avg_f1:.4f} - loss: {avg_loss:.4f} - '\n",
    "          f'precision: {avg_precision:.4f} - recall: {avg_recall:.4f} - '\n",
    "          f'val_accuracy: {avg_eval_accuracy:.4f} - val_f1_score: {avg_eval_f1:.4f} - val_loss: {avg_eval_loss:.4f} - '\n",
    "          f'val_precision: {avg_eval_precision:.4f} - val_recall: {avg_eval_recall:.4f}')\n",
    "        \n",
    "    # Возвращаемся в режим обучения\n",
    "    cnn.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0111347",
   "metadata": {},
   "source": [
    "### 5. Анализ качества"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5b19e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_accuracies)\n",
    "plt.plot(val_accuracies)\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b15d78",
   "metadata": {},
   "source": [
    "Результаты указывают на следующее:\n",
    "- Точность на обучении стабильно растёт по мере увеличения числа эпох — модель действительно учится.\n",
    "- Валидационная точность сначала улучшается, но затем колеблется — признак начинающегося переобучения.\n",
    "- После пика (около 9-й эпохи) разрыв между обучением и валидацией увеличивается.\n",
    "- Чтобы снизить переобучение, стоит рассмотреть регуляризацию (например, dropout, weight decay), раннюю остановку и/или усиление аугментаций.\n",
    "\n",
    "**Итог.** Модель уверенно осваивает тренировочные данные, но со временем переобучается. Для лучшей обобщаемости полезно добавить регуляризацию, подобрать гиперпараметры и контролировать раннюю остановку."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
